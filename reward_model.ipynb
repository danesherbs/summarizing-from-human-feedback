{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import torch\n",
    "import json\n",
    "import linecache\n",
    "import collections\n",
    "import transformers\n",
    "import os\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"comparisons/batch10.json\", \"r\") as file:\n",
    "    for i, json_str in enumerate(file):\n",
    "        obj = json.loads(json_str)\n",
    "        print(obj.keys())\n",
    "        print(obj[\"info\"])\n",
    "        print(obj[\"summaries\"])\n",
    "        print(obj[\"choice\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComparisonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_dataset_dir):\n",
    "        self.path_to_dataset_dir = path_to_dataset_dir\n",
    "        self.file_names = [f\"{path_to_dataset_dir}/batch{i}.json\" for i in range (3, 10)]\n",
    "        self.file_lengths = None\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.file_lengths is None:\n",
    "            self.file_lengths = collections.OrderedDict()\n",
    "            for file_name in self.file_names:\n",
    "                with open(file_name) as f:\n",
    "                    self.file_lengths[file_name] = sum(1 for line in f)\n",
    "        \n",
    "        return sum(self.file_lengths.values())\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        i = i % len(self)\n",
    "\n",
    "        if not (0 <= i < len(self)):\n",
    "            raise IndexError(f\"Tried to retrieve sample at index {i}, but only indicies between 0 and {len(self)-1} modulo {len(self)} are valid.\")\n",
    "        \n",
    "        cum_length = 0\n",
    "        \n",
    "        for file_name in self.file_names:\n",
    "            cum_length += self.file_lengths[file_name]\n",
    "            if i < cum_length:\n",
    "                file_idx = i - cum_length + self.file_lengths[file_name]\n",
    "                line = linecache.getline(file_name, lineno=file_idx+1)\n",
    "                payload = json.loads(line)\n",
    "                choice = payload[\"choice\"]\n",
    "                summary_good = payload[\"summaries\"][choice][\"text\"]\n",
    "                summary_bad = payload[\"summaries\"][1 - choice][\"text\"]\n",
    "                post = payload[\"info\"][\"post\"]\n",
    "                post_good = f\"{post} TLDR:{summary_good}\"\n",
    "                post_bad = f\"{post} TLDR:{summary_bad}\"\n",
    "                return post_good, post_bad\n",
    "\n",
    "\n",
    "dataset = ComparisonDataset(path_to_dataset_dir=\"./comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_non_masked_indices(mask):\n",
    "    \"\"\"\n",
    "    Adapted from https://github.com/openai/summarize-from-feedback/blob/master/summarize_from_feedback/reward_model.py\n",
    "    \"\"\"\n",
    "    bools = mask == 0\n",
    "    row_len = bools.size(-1)\n",
    "    zero_or_index = row_len * (~bools).type(torch.long) + torch.arange(\n",
    "        row_len, dtype=torch.long, device=bools.device\n",
    "    )\n",
    "    indices = torch.min(zero_or_index, dim=-1).values - 1\n",
    "    return torch.max(indices, torch.zeros([1], dtype=indices.dtype, device=mask.device))\n",
    "\n",
    "\n",
    "last_non_masked_indices(\n",
    "    mask=torch.tensor([\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 0, 0],\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_non_masked_tokens(tokens, mask):\n",
    "    last_indices = last_non_masked_indices(mask)\n",
    "    last_tokens = torch.gather(tokens, dim=-1, index=last_indices[:, None])\n",
    "    return last_tokens.squeeze(-1)\n",
    "\n",
    "def last_non_masked_tokens_test():\n",
    "    tokens = torch.tensor([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9],\n",
    "    ])\n",
    "    mask = torch.tensor([\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 0],\n",
    "        [0, 0, 0],\n",
    "    ])\n",
    "    \n",
    "    actual = last_non_masked_tokens(tokens, mask)\n",
    "    expected = torch.tensor([3, 5, 7])\n",
    "    actual_shape = actual.shape\n",
    "    expected_shape = tokens.shape[:-1]\n",
    "\n",
    "    assert torch.allclose(actual, expected)\n",
    "    assert actual_shape == expected_shape\n",
    "\n",
    "\n",
    "last_non_masked_tokens_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTWithRewardHead(torch.nn.Module):\n",
    "    def __init__(self, mask_token_id=-100):\n",
    "        super().__init__()\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.gpt = transformers.GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=mask_token_id)\n",
    "        self.gpt.load_state_dict(torch.load(\"models/baseline.pt\"))\n",
    "        self.generate = self.gpt.generate  # borrow existing generate function\n",
    "        hidden_size = self.gpt.transformer.wte.weight.shape[-1]\n",
    "        self.reward_network = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, 4 * hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4 * hidden_size, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, **kwargs):\n",
    "        response = self.gpt(input_ids, output_hidden_states=True, **kwargs)  # [batch_size, num_layers, hidden_dim]\n",
    "        last_hidden_state = response.hidden_states[-1]  # [batch_size, seq_len, hidden_size]\n",
    "        rewards = self.reward_network(last_hidden_state).squeeze(-1)  # [batch_size, seq_len]\n",
    "        last_rewards = last_non_masked_tokens(rewards, kwargs[\"attention_mask\"])\n",
    "        return last_rewards\n",
    "\n",
    "\n",
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = -100\n",
    "\n",
    "model = GPTWithRewardHead().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batches):\n",
    "    summary_good, summary_bad = zip(*batches)\n",
    "    summaries = summary_good + summary_bad\n",
    "    return tokenizer(summaries, **tokenizer_config)\n",
    "\n",
    "tokenizer_config = {\n",
    "    \"max_length\": 350,\n",
    "    \"padding\": \"longest\",\n",
    "    \"truncation\": True,\n",
    "    \"return_tensors\": \"pt\",\n",
    "}\n",
    "\n",
    "data_loader_config = {\n",
    "    \"batch_size\": 8,\n",
    "    \"shuffle\": True,\n",
    "    \"collate_fn\": collate_fn,\n",
    "    \"drop_last\": True,\n",
    "}\n",
    "\n",
    "num_train = int(0.97 * len(dataset))\n",
    "num_test = len(dataset) - num_train\n",
    "\n",
    "data_train, data_test = torch.utils.data.random_split(dataset, (num_train, num_test))\n",
    "train_data_loader = torch.utils.data.DataLoader(data_train, **data_loader_config)\n",
    "test_data_loader = torch.utils.data.DataLoader(data_test, **data_loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_number_of_tokens_in_dataset(dataset, n_samples=1_000):\n",
    "    total_length = 0\n",
    "\n",
    "    for i, (good, bad) in enumerate(dataset):\n",
    "        if i == n_samples:\n",
    "            break\n",
    "        \n",
    "        total_length += tokenizer(good, **tokenizer_config).input_ids.shape[-1]\n",
    "\n",
    "    return total_length / (i+1)\n",
    "\n",
    "\n",
    "average_number_of_tokens_in_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.split(torch.rand(16), split_size_or_sections=8, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data_loader, val_data_loader, comet_experiment, epochs=1, lr=1.5e-5):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    batch_size = train_data_loader.batch_size\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for i, inputs in enumerate(train_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = inputs[\"input_ids\"].to(DEVICE)  # [2 * batch_size, seq_len]\n",
    "            attention_mask = inputs[\"attention_mask\"].to(DEVICE)\n",
    "            rewards = model(input_ids, attention_mask=attention_mask)  # [2 * batch_size]\n",
    "            rewards_good, rewards_bad = torch.split(rewards, split_size_or_sections=batch_size, dim=0)\n",
    "\n",
    "            loss = -torch.log(torch.sigmoid(rewards_good - rewards_bad) + 1e-6).mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            comet_experiment.log_metric('train loss', float(loss))\n",
    "            comet_experiment.log_metric('avg (good - bad) rewards', float((rewards_good - rewards_bad).mean()))\n",
    "            comet_experiment.log_metric('avg good summary rewards', float(rewards_good.mean()))\n",
    "            comet_experiment.log_metric('avg bad summary rewards', float(rewards_bad.mean()))\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                model.eval()\n",
    "                n_correct = 0\n",
    "                print(\"validating\")\n",
    "                for val_inputs in val_data_loader:\n",
    "                    with torch.no_grad():\n",
    "                        input_ids = val_inputs[\"input_ids\"].to(DEVICE)  # [2 * batch_size, seq_len]\n",
    "                        attention_mask = val_inputs[\"attention_mask\"].to(DEVICE)\n",
    "                        rewards = model(input_ids, attention_mask=attention_mask)  # [2 * batch_size]\n",
    "                        # print(\"rewards.shape\", rewards.shape)\n",
    "                        # print(\"batch_size\", batch_size)\n",
    "                        rewards_good, rewards_bad = torch.split(rewards, split_size_or_sections=batch_size, dim=0)\n",
    "                        logits = torch.cat([rewards_good, rewards_bad], dim=-1)\n",
    "                        preds = torch.max(logits, dim=-1).indices\n",
    "                        targets = torch.vstack([torch.ones(batch_size), torch.zeros(batch_size)]).to(DEVICE)\n",
    "                        n_correct += torch.sum(preds == targets)\n",
    "                model.train()\n",
    "            \n",
    "            comet_experiment.log_metric('val accuracy', float(n_correct / (batch_size * len(val_data_loader))))\n",
    "    \n",
    "    comet_experiment.end()\n",
    "\n",
    "\n",
    "experiment = comet_ml.Experiment(\n",
    "    api_key=os.getenv(\"COMET_API_KEY\"),\n",
    "    project_name=\"learning-to-summarise-using-human-feedback\",\n",
    "    workspace=\"danesherbs\",\n",
    "    log_env_cpu=False,\n",
    "    log_env_gpu=False,\n",
    ")\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    train_data_loader=train_data_loader,\n",
    "    val_data_loader=test_data_loader,\n",
    "    comet_experiment=experiment,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
