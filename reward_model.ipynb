{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import torch\n",
    "import json\n",
    "import linecache\n",
    "import collections\n",
    "import transformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'split', 'summaries', 'choice', 'worker', 'batch', 'extra'])\n",
      "{'id': 't3_52mb8y', 'post': \"This is my first post so please be kind :)\\n\\nI know that lots of people often feel confused when they come out of a long-term relationship. They think they have forgotten how to be single, or how to flirt/date.\\n\\nI am one of these people.\\n\\nThe problem is, my relationship started when I had just turned 16. I have never been single - as an adult. That might sound silly. But the only time I have ever flirted or dated was as an over-confident, hormone-riddled teenager.\\n\\nNow I have a pretty demanding job, responsibilities blah blah... And I just don't know how to this!\\n\\nI'm no way in a rush to get into a new relationship, but that doesn't mean I want to be completely alone in the mean time.\\n\\nIf anyone has experienced anything similar, or just generally has some advice, it would be greatly appreciated!\", 'title': \"I [23F] have just come out of 8 year relationship. Feel like I don't know how to date/flirt. Scared will grow old with many cats. Any advice?\", 'subreddit': 'relationships'}\n",
      "[{'text': \" Just came out of 8 year relationship, don't know how to please myself or how to flirt/date. How do I do this?\", 'policy': 'sup4_t0.7', 'note': 'Ok'}, {'text': \" I never dated/flirted as an adult, now I'm not sure how to date. Scared will grow old with many cats. Any advice?\", 'policy': 'sup4_t0.7', 'note': 'Ok'}]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "with open(\"comparisons/batch10.json\", \"r\") as file:\n",
    "    for i, json_str in enumerate(file):\n",
    "        obj = json.loads(json_str)\n",
    "        print(obj.keys())\n",
    "        print(obj[\"info\"])\n",
    "        print(obj[\"summaries\"])\n",
    "        print(obj[\"choice\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComparisonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_dataset_dir):\n",
    "        self.path_to_dataset_dir = path_to_dataset_dir\n",
    "        self.file_names = [f\"{path_to_dataset_dir}/batch{i}.json\" for i in range (3, 11)]\n",
    "        self.file_lengths = None\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.file_lengths is None:\n",
    "            self.file_lengths = collections.OrderedDict()\n",
    "            for file_name in self.file_names:\n",
    "                with open(file_name) as f:\n",
    "                    self.file_lengths[file_name] = sum(1 for line in f)\n",
    "        \n",
    "        return sum(self.file_lengths.values())\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        i = i % len(self)\n",
    "\n",
    "        if not (0 <= i < len(self)):\n",
    "            raise IndexError(f\"Tried to retrieve sample at index {i}, but only indicies between 0 and {len(self)-1} modulo {len(self)} are valid.\")\n",
    "        \n",
    "        cum_length = 0\n",
    "        \n",
    "        for file_name in self.file_names:\n",
    "            cum_length += self.file_lengths[file_name]\n",
    "            if i < cum_length:\n",
    "                file_idx = i - cum_length + self.file_lengths[file_name]\n",
    "                line = linecache.getline(file_name, lineno=file_idx+1)\n",
    "                payload = json.loads(line)\n",
    "                choice = payload[\"choice\"]\n",
    "                summary_good = payload[\"summaries\"][choice][\"text\"]\n",
    "                summary_bad = payload[\"summaries\"][1 - choice][\"text\"]\n",
    "                post = payload[\"info\"][\"post\"]\n",
    "                post_good = f\"{post} TLDR:{summary_good}\"\n",
    "                post_bad = f\"{post} TLDR:{summary_bad}\"\n",
    "                return post_good, post_bad\n",
    "\n",
    "\n",
    "dataset = ComparisonDataset(path_to_dataset_dir=\"./comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103901"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A bit of background:\\n\\nAll of my exes that I have had, (with the [current] exception of my most recent one [less than two months since breakup]) are married, and all of the ones that had interest, have kids.\\n\\nEvery single one of them.\\n\\nMy most recent ex broke up with me under the guise of we needed to take a break so we were better together, and kept saying things like we needed space so we could become better for ourselves, not each other.\\nThen today I found out that not only is she with someone else in all possible ways, less than two months after our breakup, but she realized when she met him while we were still together that he was the one she was going to spend her life with. TLDR: exes who I have had breakups with all married, every single one of them, and every single one of them is with someone else less than two months after our breakup.',\n",
       " 'A bit of background:\\n\\nAll of my exes that I have had, (with the [current] exception of my most recent one [less than two months since breakup]) are married, and all of the ones that had interest, have kids.\\n\\nEvery single one of them.\\n\\nMy most recent ex broke up with me under the guise of we needed to take a break so we were better together, and kept saying things like we needed space so we could become better for ourselves, not each other.\\nThen today I found out that not only is she with someone else in all possible ways, less than two months after our breakup, but she realized when she met him while we were still together that he was the one she was going to spend her life with. TLDR: Exes keep saying they need space so they can become better for each other, but now all of them have new partners, is it time for me to move on?')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTWithRewardHead(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, mask_token_id=-100):\n",
    "        super().__init__()\n",
    "        self.gpt = transformers.GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=mask_token_id)\n",
    "        self.generate = self.gpt.generate  # borrow existing generate function\n",
    "        hidden_size = self.gpt.transformer.wte.weight.shape[-1]\n",
    "        self.reward_network = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, 4 * hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4 * hidden_size, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, **kwargs):\n",
    "        response = self.gpt(input_ids, output_hidden_states=True, **kwargs)  # [batch_size, num_layers, hidden_dim]\n",
    "        last_hidden_state = response.hidden_states[-1]  # [batch_size, seq_len, hidden_size]\n",
    "        rewards = self.reward_network(last_hidden_state).squeeze(-1)\n",
    "        last_reward = rewards[:, -1]\n",
    "        logits = response.logits  # [batch_size, seq_len, vocab_size]\n",
    "        return logits, last_reward\n",
    "\n",
    "\n",
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = -100\n",
    "model = GPTWithRewardHead().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batches):\n",
    "    summary_good, summary_bad = zip(*batches)\n",
    "    tokens_good = tokenizer(summary_good, **tokenizer_config)\n",
    "    tokens_bad = tokenizer(summary_bad, **tokenizer_config)\n",
    "    return tokens_good, tokens_bad\n",
    "\n",
    "tokenizer_config = {\n",
    "    \"max_length\": 512,\n",
    "    \"padding\": \"longest\",\n",
    "    \"truncation\": True,\n",
    "    \"return_tensors\": \"pt\",\n",
    "}\n",
    "\n",
    "data_loader_config = {\n",
    "    \"batch_size\": 4,\n",
    "    \"shuffle\": True,\n",
    "    \"collate_fn\": collate_fn,\n",
    "}\n",
    "\n",
    "num_train = int(0.95 * len(dataset))\n",
    "num_test = len(dataset) - num_train\n",
    "\n",
    "data_train, data_test = torch.utils.data.random_split(dataset, (num_train, num_test))\n",
    "train_data_loader = torch.utils.data.DataLoader(data_train, **data_loader_config)\n",
    "test_data_loader = torch.utils.data.DataLoader(data_test, **data_loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': tensor([[   40,   357,  1731,  ..., 50256, 50256, 50256],\n",
      "        [   40,  3888,   287,  ..., 50256, 50256, 50256],\n",
      "        [   40,  1053,   587,  ..., 50256, 50256, 50256],\n",
      "        [    7,  5305,  1096,  ...,   477,  1865,    13]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}, {'input_ids': tensor([[   40,   357,  1731,  ..., 50256, 50256, 50256],\n",
      "        [   40,  3888,   287,  ..., 50256, 50256, 50256],\n",
      "        [   40,  1053,   587,  ..., 50256, 50256, 50256],\n",
      "        [    7,  5305,  1096,  ...,  5876,  4547,     8]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])})\n"
     ]
    }
   ],
   "source": [
    "for x in train_data_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/danesherbs/learning-to-summarise-using-human-feedback/1868132920eb48b5acea254d777693b8\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-004157f2be55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomet_experiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-004157f2be55>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data_loader, epochs, lr, comet_experiment)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_good_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_good_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0minput_bad_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_bad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mattention_bad_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_bad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_bad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bad_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_bad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(model, train_data_loader, epochs=30, lr=1e-3, comet_experiment=None):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=50)\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for inputs_good, inputs_bad in train_data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_good_ids = inputs_good[\"input_ids\"].to(DEVICE)\n",
    "            attention_good_mask = inputs_good[\"attention_mask\"].to(DEVICE)\n",
    "            _, rewards_good = model(input_good_ids, attention_mask=attention_good_mask)\n",
    "            \n",
    "            input_bad_ids = inputs_bad[\"input_ids\"].to(DEVICE)\n",
    "            attention_bad_mask = inputs_bad[\"attention_mask\"].to(DEVICE)\n",
    "            _, rewards_bad = model(input_bad_ids, attention_mask=attention_bad_mask)\n",
    "            \n",
    "            loss = torch.log(torch.sigmoid(rewards_good - rewards_bad)).mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "            \n",
    "            if comet_experiment is not None:\n",
    "                comet_experiment.log_metric('train loss', float(loss))\n",
    "                experiment.log_metric('lr', optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    if comet_experiment is not None:\n",
    "        comet_experiment.end()\n",
    "\n",
    "\n",
    "experiment = comet_ml.Experiment(\n",
    "    api_key=os.getenv(\"COMET_API_KEY\"),\n",
    "    project_name=\"learning-to-summarise-using-human-feedback\",\n",
    "    workspace=\"danesherbs\",\n",
    "    log_env_cpu=False,\n",
    "    log_env_gpu=False,\n",
    ")\n",
    "\n",
    "train(model, train_data_loader, comet_experiment=experiment, lr=3e-5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
