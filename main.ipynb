{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "import einops\n",
    "from torchtyping import TensorType\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id).to(DEVICE)\n",
    "ref_model = transformers.GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_periods(s: str) -> int:\n",
    "    return sum(1 if c == \".\" else 0 for c in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch: int) -> float:\n",
    "    if epoch <= 40:\n",
    "        return epoch / 40\n",
    "    \n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def train(model, reference_model, num_steps, num_tokens_to_generate, batch_size, lr, kl_loss_coefficient, print_every=1, device=DEVICE):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_schedule)\n",
    "    vocab_size = len(tokenizer)\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = torch.full(size=(batch_size, 1), fill_value=tokenizer.eos_token_id).to(device)\n",
    "        response_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_length=num_tokens_to_generate,\n",
    "            min_length=num_tokens_to_generate,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=1.0,\n",
    "            top_k=vocab_size,\n",
    "        )\n",
    "        reponse_texts = tokenizer.batch_decode(response_ids)\n",
    "        rewards = torch.tensor([count_periods(response) for response in reponse_texts], dtype=torch.float32).to(device)\n",
    "        \n",
    "        rewards_mean = torch.mean(rewards, dim=-1, keepdim=True)\n",
    "        rewards_std = torch.std(rewards, dim=-1, keepdim=True)\n",
    "        rewards_normed = (rewards - rewards_mean) / (rewards_std + 1e-6)\n",
    "\n",
    "        log_probs = log_prob_from_input_ids(model, response_ids)\n",
    "        reference_log_probs = log_prob_from_input_ids(reference_model, response_ids)\n",
    "\n",
    "        probs = torch.exp(reference_log_probs)\n",
    "        reference_probs = torch.exp(reference_log_probs)\n",
    "\n",
    "        kl_loss = torch.nn.functional.kl_div(reference_probs, probs)\n",
    "        loss = -(log_probs * rewards_normed).mean() + kl_loss_coefficient * kl_loss.mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if (i+1) % print_every == 0:\n",
    "            print(f\"Step {(i+1):2} | loss {loss:.5f} | avg reward {rewards.mean():.5f} | lr {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "\n",
    "def log_prob_from_input_ids(model: torch.nn.Module, input_ids: TensorType[\"batch_size\", \"seq_len\"]) -> TensorType[\"batch_size\"]:\n",
    "    \"\"\"\n",
    "    Calculates p(x_1, x_2, ..., x_n | x_0) = p(x_1 | x_0) * p(x_2 | x_1, x_0) * ... * p(x_{n} | x_{n-1}, ..., x_0)\n",
    "    \"\"\"\n",
    "\n",
    "    logits = model(input_ids).logits[:, :-1]  # [batch_size, seq_len-1, vocab_size] -- ignore x_{n+1}\n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=-1) \n",
    "    \n",
    "    input_ids = input_ids[:, 1:]  # [batch_size, seq_len-1, vocab_size]  -- ignore x_0\n",
    "    input_ids = input_ids.unsqueeze(-1)  # [batch_size, seq_len] -> [batch_size, seq_len, 1]\n",
    "    seq_log_probs = torch.gather(input=log_probs, dim=-1, index=input_ids)\n",
    "    seq_log_probs = seq_log_probs.squeeze(-1) # [batch_size, seq_len, 1] -> [batch_size, seq_len]\n",
    "\n",
    "    return torch.sum(seq_log_probs, dim=-1)  # [batch_size,]\n",
    "\n",
    "\n",
    "# train(\n",
    "#     model=model,\n",
    "#     reference_model=ref_model,\n",
    "#     num_steps=100,\n",
    "#     num_tokens_to_generate=20,\n",
    "#     batch_size=20,\n",
    "#     lr=3e-5,\n",
    "#     kl_loss_coefficient=0.2,\n",
    "#     print_every=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first time the company has made a statement that it is not aware of a problem with']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer([\"This is\"], return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "response_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=20,\n",
    "    min_length=20,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=1.0,\n",
    "    top_k=len(tokenizer),\n",
    ")\n",
    "tokenizer.batch_decode(response_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTWithValueHead(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        self.gpt = transformers.GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=self.tokenizer.eos_token_id)\n",
    "        hidden_size = self.gpt.transformer.wte.weight.shape[-1]\n",
    "        self.value_network = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, 4 * hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4 * hidden_size, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        response = self.gpt(input_ids, output_hidden_states=True)  # [batch_size, num_layers, hidden_dim]\n",
    "        last_hidden_state = response.hidden_states[-1]  # [batch_size, seq_len, hidden_size]\n",
    "        values = self.value_network(last_hidden_state).squeeze(-1)\n",
    "        logits = response.logits  # [batch_size, seq_len, vocab_size]\n",
    "        return logits, values\n",
    "\n",
    "\n",
    "model_with_value_head = GPTWithValueHead().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/danesherbs/learning-to-summarise-using-human-feedback/53d782a1d4614750a5886a7494c6abfe\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.71381366, '<|endoftext|>'), (2.271839, '\\n'), (1.5142207, 'The'), (1.8790493, ' boy'), (1.4063834, ' who'), (1.834041, ' was'), (1.7273602, ' murdered'), (1.5485362, ' in'), (1.6271002, ' the'), (0.27771175, ' aftermath'), (1.2530975, ' of'), (1.4790462, ' the'), (1.0655807, ' Sandy'), (0.99257016, ' Hook'), (0.11359513, ' Elementary'), (0.4894036, ' School'), (1.356084, ' shooting'), (2.1453974, ' was'), (1.1290555, ' a'), (4.679453, ' 17')]\n",
      "[(1.0935266, '<|endoftext|>'), (1.0750427, 'The'), (1.3006316, ' game'), (1.2943171, ' is'), (1.2408774, ' based'), (0.96647996, ' on'), (1.0045441, ' the'), (0.85677874, ' Japanese'), (1.0331157, ' RPG'), (1.4218235, ' series'), (1.3857914, '.'), (1.4985912, ' In'), (1.2338622, ' addition'), (1.1306831, ' to'), (1.2686871, ' its'), (1.1506214, ' Japanese'), (0.55834204, ' name'), (0.92333907, ','), (1.1911438, ' the'), (1.0125614, ' game')]\n",
      "[(0.05698468, '<|endoftext|>'), (0.23794253, '\\n'), (0.045566875, 'F'), (0.2945436, 'ounded'), (0.38689086, ' in'), (0.22531565, ' 2009'), (0.3083938, ','), (0.37875673, ' the'), (0.19525273, ' Blue'), (0.2868453, ' Ridge'), (0.31855103, ' National'), (0.3901895, ' Forest'), (0.51273185, ' is'), (0.23451735, ' home'), (0.46783873, ' to'), (0.5406392, ' some'), (0.37089923, ' of'), (0.5538412, ' the'), (0.43806776, ' most'), (0.39571175, ' diverse')]\n",
      "[(0.7191358, '<|endoftext|>'), (0.5039077, 'Last'), (0.32649732, ' week'), (0.39367044, \"'s\"), (0.3377751, ' article'), (0.39695728, ' on'), (0.445696, ' the'), (0.6309539, ' White'), (0.34630036, ' House'), (0.28281403, ' website'), (0.27423966, ' was'), (0.3994199, ' headlined'), (0.5203835, ' \"'), (0.58813906, 'A'), (0.2694105, ' report'), (0.3629353, ' on'), (0.37570238, ' the'), (0.5282003, ' White'), (0.27660012, ' House'), (0.33073366, \"'s\")]\n",
      "[(0.44648936, '<|endoftext|>'), (0.42507735, '\\n'), (0.42806038, 'The'), (0.6672637, ' ability'), (0.45261207, ' to'), (0.4061909, ' convert'), (0.44438425, ' an'), (0.46014968, ' image'), (0.39959887, ' into'), (0.3419161, ' a'), (0.5943777, ' text'), (0.5667284, ' file'), (0.47941878, ' by'), (0.45154098, ' simply'), (0.4713396, ' copying'), (0.49376538, ' the'), (0.4910523, ' image'), (0.45234063, ' into'), (0.4613575, ' the'), (0.6207724, ' clipboard')]\n",
      "[(0.6460647, '<|endoftext|>'), (0.563489, 'On'), (0.62317854, ' this'), (0.6896412, ' page'), (0.8508838, ':'), (0.93178743, '\\n'), (0.8355685, '\\n'), (0.67370266, 'The'), (0.71176, ' following'), (0.6968307, ' are'), (0.64126056, ' some'), (0.6501476, ' of'), (0.69620353, ' the'), (0.60582715, ' most'), (0.7033536, ' important'), (0.61969286, ' facts'), (0.6456619, ' about'), (0.6123865, ' the'), (0.6441348, ' story'), (0.5971561, ' of')]\n",
      "[(0.59180045, '<|endoftext|>'), (0.91466844, 'You'), (0.8567947, ' could'), (0.7294991, ' argue'), (0.7645019, ' that'), (0.66914177, ' the'), (0.61266065, ' big'), (0.8329693, ' b'), (0.76391494, 'angers'), (0.66438866, ' in'), (0.6853758, ' the'), (0.73060215, ' state'), (0.6186056, ' of'), (0.75960624, ' Texas'), (0.66519177, ' were'), (0.5658555, ' the'), (0.7167162, ' drought'), (0.6730063, ','), (0.5675428, ' the'), (0.6135534, ' shale')]\n",
      "[(0.5187468, '<|endoftext|>'), (0.54344404, '\\n'), (0.577284, 'The'), (0.5851017, ' Federal'), (0.64312303, ' Reserve'), (0.62729454, ' is'), (0.5295479, ' proposing'), (0.5912509, ' a'), (0.5635365, ' $'), (0.554222, '1'), (0.546952, ' trillion'), (0.46320412, ' increase'), (0.5680263, ' in'), (0.5149034, ' interest'), (0.5648644, ' rates'), (0.5759808, ' on'), (0.6920378, ' the'), (0.62379944, ' nation'), (0.7141794, \"'s\"), (0.6363183, ' $')]\n",
      "[(0.47489953, '<|endoftext|>'), (0.0891537, '\\n'), (0.10179787, 'The'), (0.12400036, ' paper'), (0.1473425, ' has'), (0.18374008, ' been'), (0.17442542, ' published'), (0.22856694, ' in'), (0.26002365, ' the'), (0.29391295, ' Journal'), (0.285237, ' of'), (0.28400248, ' the'), (0.23979694, ' Royal'), (0.30395693, ' Society'), (0.33659977, ' Interface'), (0.6593333, '.'), (0.5098951, '\\n'), (0.6028742, '\\n'), (0.5801868, '\"'), (0.433927, 'We')]\n",
      "[(0.04765355, '<|endoftext|>'), (-0.0904739, 'The'), (-0.2961756, ' number'), (-0.25096023, ' of'), (-0.4910419, ' people'), (-0.5819465, ' killed'), (-0.416278, ' in'), (-0.4509101, ' the'), (-0.5090946, ' Afghan'), (-0.4098003, ' conflict'), (-0.49592185, ' has'), (-0.60393405, ' risen'), (-0.5433383, ' sharply'), (-0.47279525, ' in'), (-0.46821523, ' recent'), (-0.44944954, ' years'), (-0.61605406, ','), (-0.48010874, ' with'), (-0.64066255, ' more'), (-0.6358954, ' than')]\n",
      "[(0.41127613, '<|endoftext|>'), (0.8661704, 'i'), (0.59068155, 'Pad'), (0.5394668, ' Pro'), (0.56738174, ','), (0.46043196, ' iPad'), (0.6717079, ' 2'), (0.56843436, ','), (0.6048366, ' iPhone'), (0.57299984, ','), (0.5548175, ' iPod'), (0.5904213, ' Touch'), (0.529503, ','), (0.48051944, ' iPod'), (0.6369112, ' touch'), (0.81761134, ' 2'), (0.62969923, ','), (0.6642058, ' iPad'), (0.8138708, ' 2'), (0.6515058, ',')]\n",
      "[(0.37523362, '<|endoftext|>'), (0.29019985, 'These'), (0.36800334, ' are'), (0.33027908, ' the'), (0.33044598, ' steps'), (0.3414193, ' you'), (0.37355718, ' should'), (0.37792715, ' follow'), (0.40367267, ' to'), (0.3400136, ' get'), (0.41589913, ' the'), (0.31070575, ' best'), (0.3176112, ' performance'), (0.8313536, '.'), (0.8914324, '\\n'), (0.9100767, '\\n'), (0.9184505, 'Step'), (1.1819876, ' 1'), (1.8406537, '.'), (1.124844, ' Make')]\n",
      "[(0.5413546, '<|endoftext|>'), (0.4290568, 'The'), (0.2691529, ' first'), (0.30186334, ' time'), (0.16968052, ' I'), (0.17813055, ' used'), (0.23833983, ' the'), (0.25214317, ' software'), (0.22130363, ' that'), (0.17639808, ' I'), (0.1068844, ' had'), (0.14361875, ' on'), (0.20281653, ' hand'), (0.22257547, ','), (0.2611541, ' the'), (0.28975955, ' process'), (0.28410652, ' was'), (0.27276447, ' quite'), (0.40681162, ' simple'), (0.8145339, '.')]\n",
      "[(0.4969955, '<|endoftext|>'), (1.4246438, '3'), (1.5822533, '.'), (1.6644351, '6'), (1.6010798, '.'), (1.391933, '0'), (1.0009415, '\\n'), (0.8314607, '\\n'), (0.8358162, '-'), (1.0231689, ' Optim'), (1.0776138, 'ized'), (0.9525296, ' for'), (1.201906, ' Android'), (1.3001302, ' 6'), (1.5157819, '.'), (1.1620668, '0'), (1.0354788, '\\n'), (0.93801194, '\\n'), (1.1214384, '-'), (1.2671452, ' Added')]\n",
      "[(1.0527619, '<|endoftext|>'), (0.56361747, 'In'), (0.5787126, ' the'), (0.59184754, ' early'), (0.47043386, ' 1990'), (0.4548649, 's'), (0.40064028, ','), (0.42276576, ' the'), (0.39585343, ' former'), (0.3348134, ' Soviet'), (0.30854687, ' Union'), (0.2676334, \"'s\"), (0.28947118, ' defense'), (0.29837683, ' minister'), (0.29660442, ','), (0.38318846, ' Mikhail'), (0.2756386, ' Gor'), (0.3117194, 'b'), (0.1836579, 'achev'), (0.21001555, ',')]\n",
      "[(0.9224546, '<|endoftext|>'), (1.2519606, 'I'), (1.266538, \"'m\"), (1.3007692, ' not'), (1.2530471, ' sure'), (1.2462976, ' what'), (1.3235915, ' to'), (1.3312668, ' make'), (1.1847279, ' of'), (1.233814, ' all'), (1.1286259, ' the'), (1.1050098, ' positive'), (1.1524689, ' feedback'), (1.0172387, ' that'), (1.102202, ' I'), (1.1317952, ' got'), (1.0233308, ' from'), (1.0275395, ' the'), (1.0676132, ' comments'), (1.6527619, '.')]\n",
      "[(0.06850972, '<|endoftext|>'), (0.22505702, 'I'), (0.26356044, ' have'), (0.22092976, ' been'), (0.36007562, ' trying'), (0.30715206, ' to'), (0.2830706, ' figure'), (0.20148326, ' out'), (0.24539317, ' how'), (0.25557712, ' to'), (0.22014202, ' take'), (0.22287329, ' advantage'), (0.2615762, ' of'), (0.22794129, ' the'), (0.27784863, ' super'), (0.2588462, ' fast'), (0.37392882, ' file'), (0.3343511, ' transfer'), (0.28974023, ' speeds'), (0.24676849, ',')]\n",
      "[(0.9060051, '<|endoftext|>'), (0.5919274, '\\n'), (0.71407557, 'You'), (0.6446691, ' can'), (0.5566554, ' find'), (0.5317789, ' the'), (0.586222, ' full'), (0.5747843, ' list'), (0.46997485, ' of'), (0.45062068, ' the'), (0.4933801, ' open'), (0.4976292, ' source'), (0.48271957, ' projects'), (0.6219187, ' here'), (0.56171, ':'), (0.5618136, '\\n'), (0.5307957, '\\n'), (0.6672015, 'https'), (0.60639507, '://'), (0.92817616, 'github')]\n",
      "[(0.86574215, '<|endoftext|>'), (0.6208336, 'The'), (0.66736716, ' Most'), (2.04434, '.'), (2.3969233, ' Fun'), (2.705063, '.'), (2.8642707, ' Fun'), (2.4897738, 'eral'), (2.0069313, ' Home'), (2.6571648, '.'), (2.391874, '\\n'), (2.405626, '\\n'), (1.9180619, 'May'), (1.9078392, ' 17'), (1.4686679, ','), (1.5708936, ' 2008'), (1.2828746, '\\n'), (1.1812812, '\\n'), (1.1318979, 'By'), (1.1365975, ' Terry')]\n",
      "[(0.81504893, '<|endoftext|>'), (0.53814757, '\\n'), (0.558302, 'October'), (0.7609992, ' 2'), (0.61145234, ','), (0.55028987, ' 2015'), (0.4817084, '\\n'), (0.4657404, '\\n'), (0.57879615, '\"'), (0.5520161, 'There'), (0.5043726, ' are'), (0.52290916, ' no'), (0.55717856, ' words'), (0.5935842, ' to'), (0.44801986, ' describe'), (0.4736174, ' the'), (0.42366636, ' devastation'), (0.3669602, ' and'), (0.3785278, ' devastation'), (0.376582, ' that')]\n",
      "[(0.5393852, '<|endoftext|>'), (0.69244385, 'I'), (0.75363475, \"'m\"), (0.7595651, ' not'), (0.80483747, ' sure'), (0.7670343, ' what'), (0.77604795, ' to'), (0.85892576, ' make'), (0.76407516, ' of'), (0.889159, ' this'), (0.7972485, ','), (0.722786, ' but'), (0.7046187, ' I'), (0.7458223, \"'m\"), (0.7923082, ' not'), (0.85421413, ' sure'), (0.7931985, ' what'), (0.8023753, ' to'), (0.8438597, ' make'), (0.82965964, ' of')]\n",
      "[(0.27897397, '<|endoftext|>'), (0.29173514, '\\n'), (0.5252047, '\"'), (0.46890536, 'What'), (0.47008434, ' I'), (0.5320621, \"'m\"), (0.5940507, ' saying'), (0.49533775, ' is'), (0.43815336, ' that'), (0.37037405, ' I'), (0.39339957, \"'m\"), (0.39402595, ' not'), (0.34850606, ' going'), (0.38042393, ' to'), (0.3484787, ' be'), (0.38243815, ' a'), (0.3722882, ' little'), (0.34483132, ' bit'), (0.3610128, ' of'), (0.3871561, ' a')]\n",
      "[(0.40893716, '<|endoftext|>'), (0.24685997, '\\n'), (0.24302113, 'The'), (0.2911167, ' following'), (0.3321572, ' is'), (0.36558747, ' an'), (0.33124644, ' excerpt'), (0.23183432, ' from'), (0.27151006, ' the'), (0.2738895, ' book'), (0.21251446, ' The'), (0.25267476, ' Last'), (0.37357962, ' Su'), (0.27144468, 'pper'), (0.21201742, ' by'), (0.19308227, ' Kurt'), (0.12571669, ' Von'), (0.14673561, 'neg'), (0.17918062, 'ut'), (0.072327495, ',')]\n",
      "[(0.4141204, '<|endoftext|>'), (0.29293618, 'You'), (0.31750867, ' can'), (0.30250868, ' also'), (0.34653482, ' watch'), (0.298668, ' a'), (0.32557884, ' video'), (0.25847593, ' about'), (0.3570523, ' this'), (0.35137403, ' experiment'), (0.3052127, ' on'), (0.43430948, ' YouTube'), (0.8581609, '.'), (0.8419652, '\\n'), (0.83699054, '\\n'), (0.6308737, 'The'), (0.5270563, ' researchers'), (0.54618514, ' fed'), (0.50854725, ' a'), (0.52563256, ' sample')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c74312a2ff3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m train_with_value_network(\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_with_value_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mreference_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-c74312a2ff3e>\u001b[0m in \u001b[0;36mtrain_with_value_network\u001b[0;34m(model, reference_model, num_steps, num_tokens_to_generate, batch_size, lr, kl_loss_coefficient, print_every, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Rewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         response_ids = reference_model.generate(\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_tokens_to_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1134\u001b[0m             )\n\u001b[1;32m   1135\u001b[0m             return self.group_beam_search(\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0mdiverse_beam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m                 \u001b[0mAn\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStoppingCriteriaList\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0minstances\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mderived\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStoppingCriteria\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtell\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[0mloop\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m             \u001b[0mmax_length\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mint\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mDEPRECATED\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mUse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstopping_criteria\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdirectly\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m                 \u001b[0mgenerated\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m         )\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0massert_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_parallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch: int) -> float:\n",
    "    if epoch <= 40:\n",
    "        return epoch / 40\n",
    "    \n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def train_with_value_network(model, reference_model, num_steps, num_tokens_to_generate, batch_size, lr, kl_loss_coefficient, print_every=1, device=DEVICE):\n",
    "    experiment = Experiment(\n",
    "        api_key=os.getenv(\"COMET_API_KEY\"),\n",
    "        project_name=\"learning-to-summarise-using-human-feedback\",\n",
    "        workspace=\"danesherbs\",\n",
    "        log_env_cpu=False,\n",
    "        log_env_gpu=False,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_schedule)\n",
    "    \n",
    "    vocab_size = len(tokenizer)\n",
    "    seq_len = num_tokens_to_generate  # for readability\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Rewards\n",
    "        input_ids = torch.full(size=(batch_size, 1), fill_value=tokenizer.eos_token_id).to(device)\n",
    "        response_ids = reference_model.generate(\n",
    "            input_ids,\n",
    "            max_length=num_tokens_to_generate,\n",
    "            min_length=num_tokens_to_generate,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=1.0,\n",
    "            top_k=vocab_size,\n",
    "        )  # [batch_size, seq_len]\n",
    "        reponse_texts = tokenizer.batch_decode(response_ids)\n",
    "        rewards = torch.tensor([count_periods(response) for response in reponse_texts], dtype=torch.float32).to(device)  # [batch_size]\n",
    "        \n",
    "        assert response_ids.shape == (batch_size, seq_len)\n",
    "        assert rewards.shape == (batch_size,)\n",
    "        \n",
    "        rewards_mean = torch.mean(rewards, dim=-1, keepdim=True)\n",
    "        rewards_std = torch.std(rewards, dim=-1, keepdim=True)\n",
    "        rewards_normed = (rewards - rewards_mean) / (rewards_std + 1e-6)\n",
    "\n",
    "        # Query model\n",
    "        logits, values = model(response_ids)\n",
    "        assert values.shape == (batch_size, seq_len)\n",
    "        \n",
    "        # Value network\n",
    "        # shifted_values = torch.cat([values[:, 1:], torch.zeros((batch_size, 1)).to(DEVICE)], dim=-1).detach()  # [v_0, v_1, ..., v_n] -> [v_1, ..., v_n, 0]\n",
    "        shifted_values = shift_tensor_left(values).detach()\n",
    "        rewards_per_timestep = torch.cat([torch.zeros(batch_size, seq_len-1).to(DEVICE), rewards.unsqueeze(-1)], dim=-1)  # [batch_size, seq_len]\n",
    "        value_net_loss = ((values  - (rewards_per_timestep + shifted_values)) ** 2).mean()\n",
    "\n",
    "        experiment.log_metric(\"value_net_loss\", value_net_loss)\n",
    "        experiment.log_metric(\"learning_rate\", scheduler.get_last_lr()[0])\n",
    "        \n",
    "        if i % print_every == 0:\n",
    "            # print(f\"Value {list(values[0].cpu().detach().numpy())}\\nDecoded {[tokenizer.decode(tok) for tok in response_ids[0]]}\")\n",
    "            print(list(zip(list(values[0].cpu().detach().numpy()), [tokenizer.decode(tok) for tok in response_ids[0]])))\n",
    "        \n",
    "        value_net_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        continue\n",
    "        \n",
    "        # Policy network\n",
    "        reference_logits = reference_model(response_ids).logits\n",
    "        log_probs = log_probs_from_logits(logits, response_ids)\n",
    "        reference_log_probs = log_probs_from_logits(reference_logits, response_ids)\n",
    "\n",
    "        probs = torch.exp(torch.sum(reference_log_probs, dim=-1))\n",
    "        reference_probs = torch.exp(torch.sum(reference_log_probs, dim=-1))\n",
    "\n",
    "        kl_loss = torch.nn.functional.kl_div(reference_probs, probs)\n",
    "        policy_net_loss = -(log_probs * rewards_normed).mean() + kl_loss_coefficient * kl_loss.mean()\n",
    "        \n",
    "        policy_net_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if (i+1) % print_every == 0:\n",
    "            print(f\"Step {(i+1):2} | value loss {value_net_loss:.5f} | policy loss {policy_net_loss:.5f} | avg reward {rewards.mean():.5f} | value lr {value_net_scheduler.get_last_lr()[0]} | policy lr {scheduler.get_last_lr()[0]}\")\n",
    "    \n",
    "    experiment.end()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_with_value_network(\n",
    "    model=model_with_value_head,\n",
    "    reference_model=ref_model,\n",
    "    num_steps=250,\n",
    "    num_tokens_to_generate=20,\n",
    "    batch_size=40,\n",
    "    lr=3e-5,\n",
    "    kl_loss_coefficient=0.2,\n",
    "    print_every=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "tensor([[-3.0550, -8.0028]]) tensor([[[-3.0550e+00, -5.4985e-02, -5.0550e+00],\n         [-6.0028e+00, -2.8102e-03, -8.0028e+00],\n         [-3.0550e+00, -5.4985e-02, -5.0550e+00]]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e98d6b426656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_probs_from_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msoftmaxed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msoftmaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{log_probs} {softmaxed}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: tensor([[-3.0550, -8.0028]]) tensor([[[-3.0550e+00, -5.4985e-02, -5.0550e+00],\n         [-6.0028e+00, -2.8102e-03, -8.0028e+00],\n         [-3.0550e+00, -5.4985e-02, -5.0550e+00]]])"
     ]
    }
   ],
   "source": [
    "def log_probs_from_logits(logits: TensorType[\"batch_size\", \"seq_len\", \"vocab_size\"], input_ids: TensorType[\"batch_size\", \"seq_len\"]) -> TensorType[\"batch_size\", \"seq_len\"]:\n",
    "    \"\"\"\n",
    "    Calculates p(x_1, x_2, ..., x_n | x_0) = p(x_1 | x_0) * p(x_2 | x_1, x_0) * ... * p(x_{n} | x_{n-1}, ..., x_0)\n",
    "    \"\"\"\n",
    "    logits = logits[:, :-1]  # [batch_size, seq_len-1, vocab_size] -- ignore x_{n+1}\n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=-1) \n",
    "    \n",
    "    input_ids = input_ids[:, 1:]  # [batch_size, seq_len-1, vocab_size]  -- ignore x_0\n",
    "    input_ids = input_ids.unsqueeze(-1)  # [batch_size, seq_len, vocab_size, 1]\n",
    "    seq_log_probs = torch.gather(input=log_probs, dim=-1, index=input_ids)\n",
    "    seq_log_probs = seq_log_probs.squeeze(-1) # [batch_size, seq_len]\n",
    "\n",
    "    return seq_log_probs\n",
    "\n",
    "logits = torch.tensor([[[3, 6, 1], [2, 8, 0], [3, 6, 1]]], dtype=torch.float32)\n",
    "input_ids = torch.tensor([[1, 0, 2]])\n",
    "log_probs = log_probs_from_logits(logits, input_ids)\n",
    "softmaxed = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "assert torch.allclose(log_probs, torch.tensor([[softmaxed[0, 1, 0], softmaxed[0, 2, 2]]])), f\"{log_probs} {softmaxed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tensor_left(t: TensorType[\"batch_size\", \"seq_len\"]) -> TensorType[\"batch_size\", \"seq_len\"]:\n",
    "    \"\"\"\n",
    "    Shifts tensor left one and fills with zeros: [v_0, v_1, ..., v_n] -> [v_1, ..., v_n, 0].\n",
    "    \n",
    "    Note: you probably want to detach the result of this function.\n",
    "    \"\"\"\n",
    "    shifted = torch.zeros_like(t)\n",
    "    shifted[:, :-1] = t[:, 1:]\n",
    "    return shifted\n",
    "\n",
    "t = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "shifted_t = shift_tensor_left(t)\n",
    "assert torch.allclose(shifted_t, torch.tensor([[2, 3, 4, 0], [6, 7, 8, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewards_to_go_from_rewards_and_values(rewards: TensorType[\"batch_size\", \"seq_len\"], values: TensorType[\"batch_size\", \"seq_len\"]) -> TensorType[\"batch_size\", \"seq_len\"]:\n",
    "    \"\"\"\n",
    "    Computes r_t + v(s_{t+1}) - v(s_t) for t = 0, ..., T-1\n",
    "    \"\"\"\n",
    "    baseline = values\n",
    "    values_left_shifted = shift_tensor_left(values).detach()\n",
    "    # rewards_reversed = torch.flip(rewards, dim=-1)  # [r_T, ..., r_1, r_0]\n",
    "    # rewards_reversed_cumsum = torch.cumsum(rewards_reversed, dim=-1)  # [r_T + ... + r_0, r_T + ... + r_1, ..., r_T]\n",
    "    # rewards_to_go = torch.flip(rewards_reversed_cumsum)\n",
    "    return rewards + values_left_shifted - baseline\n",
    "\n",
    "rewards = torch.tensor([[0.5, 1, 0.5]])\n",
    "values = torch.tensor([[0.1, 0, 0.3]])\n",
    "rewards_to_go = rewards_to_go_from_rewards_and_values(rewards, values)\n",
    "assert torch.allclose(rewards_to_go, torch.tensor([[0.5 + 0 - 0.1, 1 + 0.3 - 0, 0.5 + 0 - 0.3]]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
