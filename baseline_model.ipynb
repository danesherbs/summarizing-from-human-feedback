{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import torch\n",
    "import json\n",
    "import linecache\n",
    "import random\n",
    "import json\n",
    "import transformers\n",
    "import einops\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tldr_dataset(n_samples=100_000):\n",
    "    linecount = 0\n",
    "    with open(\"tldr/raw_tldr.jsonl\", \"r\") as raw_file:\n",
    "        with open(\"tldr/cleaned_tldr.jsonl\", \"w\") as cleaned_file:\n",
    "            for json_str in tqdm(raw_file):\n",
    "                post = json.loads(json_str)\n",
    "                if 24 < post[\"summary_len\"] < 48:\n",
    "                    cleaned_file.write(json_str)\n",
    "                    linecount += 1\n",
    "    \n",
    "    assert n_samples <= linecount\n",
    "\n",
    "    random_idxs = random.sample(range(linecount), k=n_samples)\n",
    "    with open(\"tldr/tldr.jsonl\", \"w\") as file:\n",
    "        for i in tqdm(range(n_samples)):\n",
    "            line = linecache.getline(\"tldr/cleaned_tldr.jsonl\", lineno=random_idxs[i])\n",
    "            file.write(line)\n",
    "\n",
    "\n",
    "# create_tldr_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLDRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_tldr_dataset):\n",
    "        self.fname = path_to_tldr_dataset\n",
    "        self.len = None\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.len is None:\n",
    "            with open(self.fname) as f:\n",
    "                self.len = sum(1 for line in f)\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        i = i % len(self)\n",
    "        if not (0 <= i < len(self)):\n",
    "            raise IndexError(f\"Tried to retrieve sample at index {i}, but only indicies between 0 and {len(self)-1} modulo {len(self)} are valid.\")\n",
    "        line = linecache.getline(self.fname, lineno=i+1)\n",
    "        post = json.loads(line)\n",
    "        return post[\"normalizedBody\"]\n",
    "\n",
    "\n",
    "dataset = TLDRDataset(path_to_tldr_dataset=\"tldr/tldr.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So I'm a guy (24) and finally found someone I'm really happy with, but more importantly, comfortable with. We're dating for a month now and we seem very close to each other and seem to be overall a bit similar. \\n Still she's very experienced, having had 4 boyfriends already. Her having had more experience doesn't bother me, however my lack off scares me. I don't know how good I am, and I'm terrified that I just suck so much it will be a dealbreaker for her. \\n To add to the situation, I don't really tolerate touches, because of a traumatic past. I've worked on this, but none of this was on my intimate zones. I'm scared that I'll tense up and panick and generally make sex a lot more difficult... \\n Because this is my first real relationship, I don't really know what the best way to deal with this. \\n tl;dr: I'm a virgin who, because of his past, can't really tolerate touches. I'm really scared my lack of skill and intimacy is going to be a big dealbreaker! \\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = -100\n",
    "\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So I'm a guy (24) and finally found someone I'm really happy with, but more importantly, comfortable with. We're dating for a month now and we seem very close to each other and seem to be overall a bit similar. \\n Still she's very experienced, having had 4 boyfriends already. Her having had more experience doesn't bother me, however my lack off scares me. I don't know how good I am, and I'm terrified that I just suck so much it will be a dealbreaker for her. \\n To add to the situation, I don't really tolerate touches, because of a traumatic past. I've worked on this, but none of this was on my intimate zones. I'm scared that I'll tense up and panick and generally make sex a lot more difficult... \\n Because this is my first real relationship, I don't really know what the best way to deal with this. \\n TLDR: I'm a guy (24) and finally found someone I'm really happy with, but more importantly, comfortable with. We're dating for a month now and we seem very close to each other and seem to be overall a bit similar. \\nI'm not sure if I'm ready to go back to dating, but I'm not sure if I'm ready to go back to dating, but I'm not sure if I'm ready to go back to dating, but I'm not sure\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sample(model):\n",
    "    generate_length = 10\n",
    "    prompt = \"So I'm a guy (24) and finally found someone I'm really happy with, but more importantly, comfortable with. We're dating for a month now and we seem very close to each other and seem to be overall a bit similar. \\n Still she's very experienced, having had 4 boyfriends already. Her having had more experience doesn't bother me, however my lack off scares me. I don't know how good I am, and I'm terrified that I just suck so much it will be a dealbreaker for her. \\n To add to the situation, I don't really tolerate touches, because of a traumatic past. I've worked on this, but none of this was on my intimate zones. I'm scared that I'll tense up and panick and generally make sex a lot more difficult... \\n Because this is my first real relationship, I don't really know what the best way to deal with this. \\n TLDR\"\n",
    "    \n",
    "    input_ids = tokenizer(\n",
    "        [prompt],\n",
    "        max_length=256,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).input_ids.to(DEVICE)\n",
    "    # input_ids = input_ids[0]\n",
    "\n",
    "    response_ids = model.generate(\n",
    "        input_ids,\n",
    "        min_length=input_ids.shape[-1] + generate_length,\n",
    "        max_length=input_ids.shape[-1] + 10 * generate_length,\n",
    "        do_sample=True,\n",
    "        temperature=1e-8,\n",
    "        top_k=len(tokenizer),\n",
    "        top_p=1.0,\n",
    "    )\n",
    "\n",
    "    [decoded] = tokenizer.batch_decode(response_ids)\n",
    "\n",
    "    return decoded\n",
    "\n",
    "\n",
    "generate_sample(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch,\n",
    "        max_length=256,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "data_loader_config = {\n",
    "    \"batch_size\": 16,\n",
    "    \"shuffle\": True,\n",
    "    \"collate_fn\": collate_fn,\n",
    "}\n",
    "\n",
    "num_train = int(0.95 * len(dataset))\n",
    "num_test = len(dataset) - num_train\n",
    "\n",
    "data_train, data_val = torch.utils.data.random_split(dataset, (num_train, num_test))\n",
    "train_data_loader = torch.utils.data.DataLoader(data_train, **data_loader_config)\n",
    "test_data_loader = torch.utils.data.DataLoader(data_val, **data_loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/danesherbs/learning-to-summarise-using-human-feedback/2e4928ffe20343d5b4917f48f0c49317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_data_loader, val_data_loader, epochs=1, lr=1e-3, comet_experiment=None):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    experiment.add_tag(\"baseline_model\")\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for step, inputs in enumerate(train_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #  I    am    a    dog    [EOS]    <--- original\n",
    "            #  I    am    a    dog             <--- inputs (shifted internally)\n",
    "            #  am   a     dog  [EOS]           <--- targets (shifted internally)\n",
    "            input_ids = inputs[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = inputs[\"attention_mask\"].to(DEVICE)\n",
    "            loss = model(input_ids, attention_mask=attention_mask, labels=input_ids).loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if comet_experiment is not None:\n",
    "                comet_experiment.log_metric('train loss', float(loss))\n",
    "                experiment.log_text(generate_sample(model))\n",
    "            \n",
    "            if step % 1_000 == 0:\n",
    "                torch.save(model.state_dict(), \"models/baseline.pt\")\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                for val_inputs in val_data_loader:\n",
    "                    with torch.no_grad():\n",
    "                        input_ids = val_inputs[\"input_ids\"].to(DEVICE)\n",
    "                        attention_mask = val_inputs[\"attention_mask\"].to(DEVICE)\n",
    "                        val_loss += model(input_ids, attention_mask=attention_mask, labels=input_ids).loss\n",
    "                model.train()\n",
    "                \n",
    "                comet_experiment.log_metric('val loss', float(val_loss / len(val_data_loader)), step=step)\n",
    "    \n",
    "    if comet_experiment is not None:\n",
    "        comet_experiment.end()\n",
    "\n",
    "\n",
    "experiment = comet_ml.Experiment(\n",
    "    api_key=os.getenv(\"COMET_API_KEY\"),\n",
    "    project_name=\"learning-to-summarise-using-human-feedback\",\n",
    "    workspace=\"danesherbs\",\n",
    "    log_env_cpu=False,\n",
    "    log_env_gpu=False,\n",
    ")\n",
    "\n",
    "train(model, train_data_loader, test_data_loader, comet_experiment=experiment, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, comet_experiment=None):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    \n",
    "    for step, inputs in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            batch_loss = model(**inputs, labels=inputs[\"input_ids\"]).loss\n",
    "            loss += batch_loss\n",
    "\n",
    "        if comet_experiment is not None:\n",
    "            comet_experiment.log_metric('batch test loss', float(loss))\n",
    "    \n",
    "    if comet_experiment is not None:\n",
    "        comet_experiment.log_metric('test loss', float(loss) / (step + 1))\n",
    "        comet_experiment.end()\n",
    "\n",
    "\n",
    "# evaluate(model, test_data_loader, comet_experiment=experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.tensor([1, 1, 1, 0]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
